{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-T5/T5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Sentence pairs in English-Hindi - 2025-02-11.tsv\",sep=\"\\t\",header=None,\n",
    "                   names=[\"SrcSentenceID\",\"SrcSentence\",\"DstSentenceID\",\"DstSentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>485968</td>\n",
       "      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>2060319</td>\n",
       "      <td>म्यूरियल अब बीस साल की है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>Education in this world disappoints me.</td>\n",
       "      <td>485564</td>\n",
       "      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>That won't happen.</td>\n",
       "      <td>2060320</td>\n",
       "      <td>वैसा नहीं होगा।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>I miss you.</td>\n",
       "      <td>2060321</td>\n",
       "      <td>मुझें तुम्हारी याद आ रही है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                              SrcSentence  DstSentenceID  \\\n",
       "0           1282                       Muiriel is 20 now.         485968   \n",
       "1           1282                       Muiriel is 20 now.        2060319   \n",
       "2           1294  Education in this world disappoints me.         485564   \n",
       "3           1302                       That won't happen.        2060320   \n",
       "4           1308                              I miss you.        2060321   \n",
       "\n",
       "                                   DstSentence  \n",
       "0             म्यूरियल अब बीस साल की हो गई है।  \n",
       "1                   म्यूरियल अब बीस साल की है।  \n",
       "2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n",
       "3                              वैसा नहीं होगा।  \n",
       "4                 मुझें तुम्हारी याद आ रही है।  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(lambda x: indic_tokenize.trivial_tokenize(x,lang=\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n",
       "      <td>485564</td>\n",
       "      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[वैसा, नहीं, होगा, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[▁I, ▁miss, ▁you, .]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                                        SrcSentence  \\\n",
       "0           1282                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n",
       "1           1282                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n",
       "2           1294  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n",
       "3           1302                    [▁That, ▁won, ', t, ▁happen, .]   \n",
       "4           1308                               [▁I, ▁miss, ▁you, .]   \n",
       "\n",
       "   DstSentenceID                                        DstSentence  \n",
       "0         485968        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n",
       "1        2060319                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n",
       "2         485564  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n",
       "3        2060320                              [वैसा, नहीं, होगा, ।]  \n",
       "4        2060321              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.convert_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vd = set()\n",
    "for tokenized_hindi_sentence in data[\"DstSentence\"]:\n",
    "    Vd.update(tokenized_hindi_sentence)\n",
    "\n",
    "hindi_vocab = dict()\n",
    "for idx, token in enumerate(Vd):\n",
    "    hindi_vocab[token] = idx + 3\n",
    "\n",
    "hindi_vocab[\"<PAD>\"] = 0\n",
    "hindi_vocab[\"<SOS>\"] = 1\n",
    "hindi_vocab[\"<EOS>\"] = 2\n",
    "\n",
    "Vd = hindi_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[वैसा, नहीं, होगा, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \n",
       "0        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n",
       "1                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n",
       "2  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n",
       "3                              [वैसा, नहीं, होगा, ।]  \n",
       "4              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hindi_tokens_to_ids(tokenized_hindi_sentence):\n",
    "    return [Vd[token] for token in tokenized_hindi_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(convert_hindi_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 1139, 2913]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[6905, 3029, 2698, 2913]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[703, 6697, 2700, 2163, 5932, 1139, 2913]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \n",
       "0  [2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...  \n",
       "1         [2581, 4662, 6895, 6530, 3768, 1139, 2913]  \n",
       "2  [1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...  \n",
       "3                           [6905, 3029, 2698, 2913]  \n",
       "4          [703, 6697, 2700, 2163, 5932, 1139, 2913]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sos_token_id(hindi_sentence_token_ids_list):\n",
    "    return [1] + hindi_sentence_token_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_eos_token_id(hindi_sentence_token_ids_list):\n",
    "    return hindi_sentence_token_ids_list + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentenceInput\"] = data[\"DstSentence\"].apply(insert_sos_token_id)\n",
    "data[\"DstSentenceLabel\"] = data[\"DstSentence\"].apply(insert_eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "      <th>DstSentenceInput</th>\n",
       "      <th>DstSentenceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...</td>\n",
       "      <td>[1, 2581, 4662, 6895, 6530, 3768, 2817, 2610, ...</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 1139, 2913]</td>\n",
       "      <td>[1, 2581, 4662, 6895, 6530, 3768, 1139, 2913]</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 1139, 2913, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...</td>\n",
       "      <td>[1, 1883, 6112, 6520, 2374, 3397, 6070, 1502, ...</td>\n",
       "      <td>[1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[6905, 3029, 2698, 2913]</td>\n",
       "      <td>[1, 6905, 3029, 2698, 2913]</td>\n",
       "      <td>[6905, 3029, 2698, 2913, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[703, 6697, 2700, 2163, 5932, 1139, 2913]</td>\n",
       "      <td>[1, 703, 6697, 2700, 2163, 5932, 1139, 2913]</td>\n",
       "      <td>[703, 6697, 2700, 2163, 5932, 1139, 2913, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \\\n",
       "0  [2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...   \n",
       "1         [2581, 4662, 6895, 6530, 3768, 1139, 2913]   \n",
       "2  [1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...   \n",
       "3                           [6905, 3029, 2698, 2913]   \n",
       "4          [703, 6697, 2700, 2163, 5932, 1139, 2913]   \n",
       "\n",
       "                                    DstSentenceInput  \\\n",
       "0  [1, 2581, 4662, 6895, 6530, 3768, 2817, 2610, ...   \n",
       "1      [1, 2581, 4662, 6895, 6530, 3768, 1139, 2913]   \n",
       "2  [1, 1883, 6112, 6520, 2374, 3397, 6070, 1502, ...   \n",
       "3                        [1, 6905, 3029, 2698, 2913]   \n",
       "4       [1, 703, 6697, 2700, 2163, 5932, 1139, 2913]   \n",
       "\n",
       "                                    DstSentenceLabel  \n",
       "0  [2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...  \n",
       "1      [2581, 4662, 6895, 6530, 3768, 1139, 2913, 2]  \n",
       "2  [1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...  \n",
       "3                        [6905, 3029, 2698, 2913, 2]  \n",
       "4       [703, 6697, 2700, 2163, 5932, 1139, 2913, 2]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=[\"SrcSentenceID\",\"DstSentenceID\",\"DstSentence\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceInput</th>\n",
       "      <th>DstSentenceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>[1, 2581, 4662, 6895, 6530, 3768, 2817, 2610, ...</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>[1, 2581, 4662, 6895, 6530, 3768, 1139, 2913]</td>\n",
       "      <td>[2581, 4662, 6895, 6530, 3768, 1139, 2913, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>[1, 1883, 6112, 6520, 2374, 3397, 6070, 1502, ...</td>\n",
       "      <td>[1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>[1, 6905, 3029, 2698, 2913]</td>\n",
       "      <td>[6905, 3029, 2698, 2913, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>[1, 703, 6697, 2700, 2163, 5932, 1139, 2913]</td>\n",
       "      <td>[703, 6697, 2700, 2163, 5932, 1139, 2913, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SrcSentence  \\\n",
       "0     [4159, 23, 14018, 19, 460, 230, 5]   \n",
       "1     [4159, 23, 14018, 19, 460, 230, 5]   \n",
       "2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n",
       "3            [466, 751, 31, 17, 1837, 5]   \n",
       "4                      [27, 3041, 25, 5]   \n",
       "\n",
       "                                    DstSentenceInput  \\\n",
       "0  [1, 2581, 4662, 6895, 6530, 3768, 2817, 2610, ...   \n",
       "1      [1, 2581, 4662, 6895, 6530, 3768, 1139, 2913]   \n",
       "2  [1, 1883, 6112, 6520, 2374, 3397, 6070, 1502, ...   \n",
       "3                        [1, 6905, 3029, 2698, 2913]   \n",
       "4       [1, 703, 6697, 2700, 2163, 5932, 1139, 2913]   \n",
       "\n",
       "                                    DstSentenceLabel  \n",
       "0  [2581, 4662, 6895, 6530, 3768, 2817, 2610, 113...  \n",
       "1      [2581, 4662, 6895, 6530, 3768, 1139, 2913, 2]  \n",
       "2  [1883, 6112, 6520, 2374, 3397, 6070, 1502, 68,...  \n",
       "3                        [6905, 3029, 2698, 2913, 2]  \n",
       "4       [703, 6697, 2700, 2163, 5932, 1139, 2913, 2]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data[\"SrcSentence\"])\n",
    "Y_input = list(data[\"DstSentenceInput\"])\n",
    "Y_label = list(data[\"DstSentenceLabel\"])\n",
    "\n",
    "X_tensor = [torch.tensor(eng_tokenized_ids) for eng_tokenized_ids in X]\n",
    "Y_input_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_input]\n",
    "Y_label_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_label]\n",
    "\n",
    "X_padded = torch.nn.utils.rnn.pad_sequence(X_tensor,batch_first=True)\n",
    "Y_input_padded = torch.nn.utils.rnn.pad_sequence(Y_input_tensor,batch_first=True)\n",
    "Y_label_padded = torch.nn.utils.rnn.pad_sequence(Y_label_tensor,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = X_padded.shape[1]\n",
    "Nd = Y_label_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "        self.attention_probabilities = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,encoder_outputs,decoder_lstm_layer_outputs):\n",
    "        \n",
    "        decoder_lstm_layer_outputs = torch.transpose(decoder_lstm_layer_outputs,dim0=1,dim1=2)\n",
    "        alignment_scores = torch.bmm(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        attention_weights = self.attention_probabilities(alignment_scores)\n",
    "        attention_weights = torch.transpose(attention_weights,dim0=1,dim1=2)\n",
    "        context_vectors = torch.bmm(attention_weights,encoder_outputs)\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,topic_vector_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.first_emebdding_layer = torch.nn.Embedding(num_embeddings=src_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        \n",
    "    def forward(self,X_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_emebdding_layer(X_padded_mini_batch)\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.second_lstm_layer(first_embedding_layer_out)\n",
    "\n",
    "        return encoder_outputs,(final_encoder_output,final_candidate_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.first_embedding_layer = torch.nn.Embedding(num_embeddings=dst_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        self.attention_layer = Attention()\n",
    "        self.output_layer = torch.nn.Linear(in_features=topic_vector_dim*2,out_features=dst_lang_vocab_size)\n",
    "        self.output_layer_activation = torch.nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self,encoder_outputs,initial_hidden_state,initial_candidate_cell_state,\n",
    "                Y_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_embedding_layer(Y_padded_mini_batch)\n",
    "        decoder_lstm_layer_outputs,final_cell_hidden_states = self.second_lstm_layer(first_embedding_layer_out,\n",
    "                                                                                    (initial_hidden_state,\n",
    "                                                                                    initial_candidate_cell_state))\n",
    "        context_vectors = self.attention_layer(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        concatenated_lstm_layer_output = torch.concatenate(tensors=(decoder_lstm_layer_outputs,context_vectors),dim=2)\n",
    "        affine_transformed_output = self.output_layer(concatenated_lstm_layer_output)\n",
    "        decoder_outputs = self.output_layer_activation(affine_transformed_output)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncDecWithAttn(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Seq2SeqEncDecWithAttn,self).__init__()\n",
    "        self.encoder = Encoder(src_lang_vocab_size,topic_vector_dim)\n",
    "        self.decoder = Decoder(dst_lang_vocab_size,topic_vector_dim)\n",
    "\n",
    "    def forward(self,X_padded_mini_batch,Y_padded_mini_batch_input):\n",
    "\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.encoder(X_padded_mini_batch)\n",
    "        Y_hat_mini_batch = self.decoder(encoder_outputs,final_encoder_output,final_candidate_cell_state,\n",
    "                                       Y_padded_mini_batch_input)\n",
    "        \n",
    "        return Y_hat_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_train = X_padded[0:13000]\n",
    "Y_input_padded_train = Y_input_padded[0:13000]\n",
    "Y_label_padded_train = Y_label_padded[0:13000]\n",
    "\n",
    "X_padded_test = X_padded[13000:]\n",
    "Y_input_padded_test = Y_input_padded[13000:]\n",
    "Y_label_padded_test = Y_label_padded[13000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Mini Batch #0, CCE Loss = 8.863913536071777\n",
      "Epoch #0, Mini Batch #25, CCE Loss = 7.97291898727417\n",
      "Epoch #0, Mini Batch #50, CCE Loss = 7.980169296264648\n",
      "Epoch #0, Mini Batch #75, CCE Loss = 7.978438377380371\n",
      "Epoch #0, Mini Batch #100, CCE Loss = 7.994837284088135\n",
      "Epoch #0, Mini Batch #125, CCE Loss = 7.977851867675781\n",
      "Epoch #0, Mini Batch #150, CCE Loss = 7.960387706756592\n",
      "Epoch #0, Mini Batch #175, CCE Loss = 7.976157188415527\n",
      "Epoch #0, Mini Batch #200, CCE Loss = 7.948882579803467\n",
      "Epoch #0, Mini Batch #225, CCE Loss = 7.947870254516602\n",
      "Epoch #0, Mini Batch #250, CCE Loss = 7.956089496612549\n",
      "Epoch #0, Mini Batch #275, CCE Loss = 7.956339359283447\n",
      "Epoch #0, Mini Batch #300, CCE Loss = 7.93710994720459\n",
      "Epoch #0, Mini Batch #325, CCE Loss = 7.987609386444092\n",
      "Epoch #0, Mini Batch #350, CCE Loss = 7.954657077789307\n",
      "Epoch #0, Mini Batch #375, CCE Loss = 7.9416656494140625\n",
      "Epoch #0, Mini Batch #400, CCE Loss = 7.956364631652832\n",
      "Epoch #0, Mini Batch #425, CCE Loss = 7.959736347198486\n",
      "Epoch #0, Mini Batch #450, CCE Loss = 7.949559688568115\n",
      "Epoch #0, Mini Batch #475, CCE Loss = 7.941634178161621\n",
      "Epoch #1, Mini Batch #0, CCE Loss = 7.9388108253479\n",
      "Epoch #1, Mini Batch #25, CCE Loss = 7.9648261070251465\n",
      "Epoch #1, Mini Batch #50, CCE Loss = 7.976136684417725\n",
      "Epoch #1, Mini Batch #75, CCE Loss = 7.971045970916748\n",
      "Epoch #1, Mini Batch #100, CCE Loss = 7.994234561920166\n",
      "Epoch #1, Mini Batch #125, CCE Loss = 7.977266788482666\n",
      "Epoch #1, Mini Batch #150, CCE Loss = 7.956343650817871\n",
      "Epoch #1, Mini Batch #175, CCE Loss = 7.970482349395752\n",
      "Epoch #1, Mini Batch #200, CCE Loss = 7.947873115539551\n",
      "Epoch #1, Mini Batch #225, CCE Loss = 7.946160316467285\n",
      "Epoch #1, Mini Batch #250, CCE Loss = 7.9558000564575195\n",
      "Epoch #1, Mini Batch #275, CCE Loss = 7.951813697814941\n",
      "Epoch #1, Mini Batch #300, CCE Loss = 7.9354248046875\n",
      "Epoch #1, Mini Batch #325, CCE Loss = 7.987447738647461\n",
      "Epoch #1, Mini Batch #350, CCE Loss = 7.954641819000244\n",
      "Epoch #1, Mini Batch #375, CCE Loss = 7.9416327476501465\n",
      "Epoch #1, Mini Batch #400, CCE Loss = 7.956337928771973\n",
      "Epoch #1, Mini Batch #425, CCE Loss = 7.959731578826904\n",
      "Epoch #1, Mini Batch #450, CCE Loss = 7.949551105499268\n",
      "Epoch #1, Mini Batch #475, CCE Loss = 7.941632270812988\n",
      "Epoch #2, Mini Batch #0, CCE Loss = 7.938810348510742\n",
      "Epoch #2, Mini Batch #25, CCE Loss = 7.964832782745361\n",
      "Epoch #2, Mini Batch #50, CCE Loss = 7.976134300231934\n",
      "Epoch #2, Mini Batch #75, CCE Loss = 7.971044063568115\n",
      "Epoch #2, Mini Batch #100, CCE Loss = 7.994234085083008\n",
      "Epoch #2, Mini Batch #125, CCE Loss = 7.977267265319824\n",
      "Epoch #2, Mini Batch #150, CCE Loss = 7.956337928771973\n",
      "Epoch #2, Mini Batch #175, CCE Loss = 7.970478534698486\n",
      "Epoch #2, Mini Batch #200, CCE Loss = 7.947854042053223\n",
      "Epoch #2, Mini Batch #225, CCE Loss = 7.946156978607178\n",
      "Epoch #2, Mini Batch #250, CCE Loss = 7.955772399902344\n",
      "Epoch #2, Mini Batch #275, CCE Loss = 7.951813697814941\n",
      "Epoch #2, Mini Batch #300, CCE Loss = 7.935413837432861\n",
      "Epoch #2, Mini Batch #325, CCE Loss = 7.987448215484619\n",
      "Epoch #2, Mini Batch #350, CCE Loss = 7.954638957977295\n",
      "Epoch #2, Mini Batch #375, CCE Loss = 7.9416327476501465\n",
      "Epoch #2, Mini Batch #400, CCE Loss = 7.956340312957764\n",
      "Epoch #2, Mini Batch #425, CCE Loss = 7.959731578826904\n",
      "Epoch #2, Mini Batch #450, CCE Loss = 7.949550628662109\n",
      "Epoch #2, Mini Batch #475, CCE Loss = 7.941632270812988\n",
      "Epoch #3, Mini Batch #0, CCE Loss = 7.9388041496276855\n",
      "Epoch #3, Mini Batch #25, CCE Loss = 7.964822292327881\n",
      "Epoch #3, Mini Batch #50, CCE Loss = 7.976134300231934\n",
      "Epoch #3, Mini Batch #75, CCE Loss = 7.971044063568115\n",
      "Epoch #3, Mini Batch #100, CCE Loss = 7.99423360824585\n",
      "Epoch #3, Mini Batch #125, CCE Loss = 7.977264881134033\n",
      "Epoch #3, Mini Batch #150, CCE Loss = 7.956337928771973\n",
      "Epoch #3, Mini Batch #175, CCE Loss = 7.970478534698486\n",
      "Epoch #3, Mini Batch #200, CCE Loss = 7.947859764099121\n",
      "Epoch #3, Mini Batch #225, CCE Loss = 7.946156978607178\n",
      "Epoch #3, Mini Batch #250, CCE Loss = 7.955772399902344\n",
      "Epoch #3, Mini Batch #275, CCE Loss = 7.951813220977783\n",
      "Epoch #3, Mini Batch #300, CCE Loss = 7.935410499572754\n",
      "Epoch #3, Mini Batch #325, CCE Loss = 7.987451076507568\n",
      "Epoch #3, Mini Batch #350, CCE Loss = 7.954641819000244\n",
      "Epoch #3, Mini Batch #375, CCE Loss = 7.941632270812988\n",
      "Epoch #3, Mini Batch #400, CCE Loss = 7.9563398361206055\n",
      "Epoch #3, Mini Batch #425, CCE Loss = 7.959731578826904\n",
      "Epoch #3, Mini Batch #450, CCE Loss = 7.949550628662109\n",
      "Epoch #3, Mini Batch #475, CCE Loss = 7.941632270812988\n",
      "Epoch #4, Mini Batch #0, CCE Loss = 7.9388041496276855\n",
      "Epoch #4, Mini Batch #25, CCE Loss = 7.964822769165039\n",
      "Epoch #4, Mini Batch #50, CCE Loss = 7.975574493408203\n",
      "Epoch #4, Mini Batch #75, CCE Loss = 7.970130443572998\n",
      "Epoch #4, Mini Batch #100, CCE Loss = 7.990169048309326\n",
      "Epoch #4, Mini Batch #125, CCE Loss = 7.9724249839782715\n",
      "Epoch #4, Mini Batch #150, CCE Loss = 7.954125881195068\n",
      "Epoch #4, Mini Batch #175, CCE Loss = 7.964334964752197\n",
      "Epoch #4, Mini Batch #200, CCE Loss = 7.947397708892822\n",
      "Epoch #4, Mini Batch #225, CCE Loss = 7.945037364959717\n",
      "Epoch #4, Mini Batch #250, CCE Loss = 7.954945087432861\n",
      "Epoch #4, Mini Batch #275, CCE Loss = 7.946139335632324\n",
      "Epoch #4, Mini Batch #300, CCE Loss = 7.933200359344482\n",
      "Epoch #4, Mini Batch #325, CCE Loss = 7.979035377502441\n",
      "Epoch #4, Mini Batch #350, CCE Loss = 7.950562477111816\n",
      "Epoch #4, Mini Batch #375, CCE Loss = 7.9416327476501465\n",
      "Epoch #4, Mini Batch #400, CCE Loss = 7.946784496307373\n",
      "Epoch #4, Mini Batch #425, CCE Loss = 7.956061840057373\n",
      "Epoch #4, Mini Batch #450, CCE Loss = 7.948448181152344\n",
      "Epoch #4, Mini Batch #475, CCE Loss = 7.939424991607666\n"
     ]
    }
   ],
   "source": [
    "nw = Seq2SeqEncDecWithAttn(src_lang_vocab_size=len(Vs),dst_lang_vocab_size=len(Vd),topic_vector_dim=32)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(params=nw.parameters())\n",
    "epochs = 5\n",
    "mb_size = 26\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(X_padded_train.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = X_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_input_train_mb = Y_input_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_label_train_mb = Y_label_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "\n",
    "        Y_label_train_mb = Y_label_train_mb.reshape(Y_label_train_mb.shape[0]*Y_label_train_mb.shape[1],)\n",
    "\n",
    "        Y_pred_train_mb = nw(X_train_mb,Y_input_train_mb)\n",
    "        Y_pred_train_mb = Y_pred_train_mb.reshape(Y_pred_train_mb.shape[0]*Y_pred_train_mb.shape[1],\n",
    "                                                  Y_pred_train_mb.shape[2])\n",
    "        \n",
    "\n",
    "        loss_fn_value = loss_fn(Y_pred_train_mb,Y_label_train_mb)\n",
    "\n",
    "        loss_fn_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(\"Epoch #{}, Mini Batch #{}, CCE Loss = {}\".format(epoch,i,loss_fn_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(eng_sentence):\n",
    "\n",
    "    tokenized_eng_sentence = tokenizer.tokenize(eng_sentence)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokenized_eng_sentence)\n",
    "    token_ids_tensor = torch.tensor(token_ids)\n",
    "    padded_token_ids = torch.nn.utils.rnn.pad_sequence(token_ids_tensor)\n",
    "\n",
    "    decoder_first_time_step_output = nw(padded_token_ids,torch.tensor(hindi_vocab[\"<SOS\"]))\n",
    "    first_generated_token = np.argmax(decoder_first_time_step_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
