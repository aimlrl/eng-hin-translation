{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-T5/T5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Sentence pairs in English-Hindi - 2025-02-11.tsv\",sep=\"\\t\",header=None,\n",
    "                   names=[\"SrcSentenceID\",\"SrcSentence\",\"DstSentenceID\",\"DstSentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>485968</td>\n",
       "      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>2060319</td>\n",
       "      <td>म्यूरियल अब बीस साल की है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>Education in this world disappoints me.</td>\n",
       "      <td>485564</td>\n",
       "      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>That won't happen.</td>\n",
       "      <td>2060320</td>\n",
       "      <td>वैसा नहीं होगा।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>I miss you.</td>\n",
       "      <td>2060321</td>\n",
       "      <td>मुझें तुम्हारी याद आ रही है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                              SrcSentence  DstSentenceID  \\\n",
       "0           1282                       Muiriel is 20 now.         485968   \n",
       "1           1282                       Muiriel is 20 now.        2060319   \n",
       "2           1294  Education in this world disappoints me.         485564   \n",
       "3           1302                       That won't happen.        2060320   \n",
       "4           1308                              I miss you.        2060321   \n",
       "\n",
       "                                   DstSentence  \n",
       "0             म्यूरियल अब बीस साल की हो गई है।  \n",
       "1                   म्यूरियल अब बीस साल की है।  \n",
       "2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n",
       "3                              वैसा नहीं होगा।  \n",
       "4                 मुझें तुम्हारी याद आ रही है।  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(lambda x: indic_tokenize.trivial_tokenize(x,lang=\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n",
       "      <td>485564</td>\n",
       "      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[वैसा, नहीं, होगा, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[▁I, ▁miss, ▁you, .]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                                        SrcSentence  \\\n",
       "0           1282                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n",
       "1           1282                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n",
       "2           1294  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n",
       "3           1302                    [▁That, ▁won, ', t, ▁happen, .]   \n",
       "4           1308                               [▁I, ▁miss, ▁you, .]   \n",
       "\n",
       "   DstSentenceID                                        DstSentence  \n",
       "0         485968        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n",
       "1        2060319                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n",
       "2         485564  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n",
       "3        2060320                              [वैसा, नहीं, होगा, ।]  \n",
       "4        2060321              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.convert_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vd = set()\n",
    "for tokenized_hindi_sentence in data[\"DstSentence\"]:\n",
    "    Vd.update(tokenized_hindi_sentence)\n",
    "\n",
    "hindi_vocab = dict()\n",
    "for idx, token in enumerate(Vd):\n",
    "    hindi_vocab[token] = idx + 3\n",
    "\n",
    "hindi_vocab[\"<PAD>\"] = 0\n",
    "hindi_vocab[\"<SOS>\"] = 1\n",
    "hindi_vocab[\"<EOS>\"] = 2\n",
    "\n",
    "Vd = hindi_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[वैसा, नहीं, होगा, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \n",
       "0        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n",
       "1                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n",
       "2  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n",
       "3                              [वैसा, नहीं, होगा, ।]  \n",
       "4              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hindi_tokens_to_ids(tokenized_hindi_sentence):\n",
    "    return [Vd[token] for token in tokenized_hindi_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(convert_hindi_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 3540, 1482]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[796, 3173, 4384, 1482]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[1564, 4823, 4494, 4279, 523, 3540, 1482]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \n",
       "0  [1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...  \n",
       "1         [1721, 4743, 6932, 2032, 5130, 3540, 1482]  \n",
       "2  [5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...  \n",
       "3                            [796, 3173, 4384, 1482]  \n",
       "4          [1564, 4823, 4494, 4279, 523, 3540, 1482]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sos_token_id(hindi_sentence_token_ids_list):\n",
    "    return [1] + hindi_sentence_token_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_eos_token_id(hindi_sentence_token_ids_list):\n",
    "    return hindi_sentence_token_ids_list + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentenceInput\"] = data[\"DstSentence\"].apply(insert_sos_token_id)\n",
    "data[\"DstSentenceLabel\"] = data[\"DstSentence\"].apply(insert_eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "      <th>DstSentenceInput</th>\n",
       "      <th>DstSentenceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...</td>\n",
       "      <td>[1, 1721, 4743, 6932, 2032, 5130, 493, 1034, 3...</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 3540, 1482]</td>\n",
       "      <td>[1, 1721, 4743, 6932, 2032, 5130, 3540, 1482]</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 3540, 1482, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...</td>\n",
       "      <td>[1, 5200, 4906, 5225, 895, 3358, 304, 3450, 32...</td>\n",
       "      <td>[5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[796, 3173, 4384, 1482]</td>\n",
       "      <td>[1, 796, 3173, 4384, 1482]</td>\n",
       "      <td>[796, 3173, 4384, 1482, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[1564, 4823, 4494, 4279, 523, 3540, 1482]</td>\n",
       "      <td>[1, 1564, 4823, 4494, 4279, 523, 3540, 1482]</td>\n",
       "      <td>[1564, 4823, 4494, 4279, 523, 3540, 1482, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \\\n",
       "0  [1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...   \n",
       "1         [1721, 4743, 6932, 2032, 5130, 3540, 1482]   \n",
       "2  [5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...   \n",
       "3                            [796, 3173, 4384, 1482]   \n",
       "4          [1564, 4823, 4494, 4279, 523, 3540, 1482]   \n",
       "\n",
       "                                    DstSentenceInput  \\\n",
       "0  [1, 1721, 4743, 6932, 2032, 5130, 493, 1034, 3...   \n",
       "1      [1, 1721, 4743, 6932, 2032, 5130, 3540, 1482]   \n",
       "2  [1, 5200, 4906, 5225, 895, 3358, 304, 3450, 32...   \n",
       "3                         [1, 796, 3173, 4384, 1482]   \n",
       "4       [1, 1564, 4823, 4494, 4279, 523, 3540, 1482]   \n",
       "\n",
       "                                    DstSentenceLabel  \n",
       "0  [1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...  \n",
       "1      [1721, 4743, 6932, 2032, 5130, 3540, 1482, 2]  \n",
       "2  [5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...  \n",
       "3                         [796, 3173, 4384, 1482, 2]  \n",
       "4       [1564, 4823, 4494, 4279, 523, 3540, 1482, 2]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=[\"SrcSentenceID\",\"DstSentenceID\",\"DstSentence\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceInput</th>\n",
       "      <th>DstSentenceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>[1, 1721, 4743, 6932, 2032, 5130, 493, 1034, 3...</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>[1, 1721, 4743, 6932, 2032, 5130, 3540, 1482]</td>\n",
       "      <td>[1721, 4743, 6932, 2032, 5130, 3540, 1482, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>[1, 5200, 4906, 5225, 895, 3358, 304, 3450, 32...</td>\n",
       "      <td>[5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>[1, 796, 3173, 4384, 1482]</td>\n",
       "      <td>[796, 3173, 4384, 1482, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>[1, 1564, 4823, 4494, 4279, 523, 3540, 1482]</td>\n",
       "      <td>[1564, 4823, 4494, 4279, 523, 3540, 1482, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SrcSentence  \\\n",
       "0     [4159, 23, 14018, 19, 460, 230, 5]   \n",
       "1     [4159, 23, 14018, 19, 460, 230, 5]   \n",
       "2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n",
       "3            [466, 751, 31, 17, 1837, 5]   \n",
       "4                      [27, 3041, 25, 5]   \n",
       "\n",
       "                                    DstSentenceInput  \\\n",
       "0  [1, 1721, 4743, 6932, 2032, 5130, 493, 1034, 3...   \n",
       "1      [1, 1721, 4743, 6932, 2032, 5130, 3540, 1482]   \n",
       "2  [1, 5200, 4906, 5225, 895, 3358, 304, 3450, 32...   \n",
       "3                         [1, 796, 3173, 4384, 1482]   \n",
       "4       [1, 1564, 4823, 4494, 4279, 523, 3540, 1482]   \n",
       "\n",
       "                                    DstSentenceLabel  \n",
       "0  [1721, 4743, 6932, 2032, 5130, 493, 1034, 3540...  \n",
       "1      [1721, 4743, 6932, 2032, 5130, 3540, 1482, 2]  \n",
       "2  [5200, 4906, 5225, 895, 3358, 304, 3450, 3263,...  \n",
       "3                         [796, 3173, 4384, 1482, 2]  \n",
       "4       [1564, 4823, 4494, 4279, 523, 3540, 1482, 2]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data[\"SrcSentence\"])\n",
    "Y_input = list(data[\"DstSentenceInput\"])\n",
    "Y_label = list(data[\"DstSentenceLabel\"])\n",
    "\n",
    "X_tensor = [torch.tensor(eng_tokenized_ids) for eng_tokenized_ids in X]\n",
    "Y_input_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_input]\n",
    "Y_label_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_label]\n",
    "\n",
    "X_padded = torch.nn.utils.rnn.pad_sequence(X_tensor,batch_first=True)\n",
    "Y_input_padded = torch.nn.utils.rnn.pad_sequence(Y_input_tensor,batch_first=True)\n",
    "Y_label_padded = torch.nn.utils.rnn.pad_sequence(Y_label_tensor,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = X_padded.shape[1]\n",
    "Nd = Y_label_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "        self.attention_probabilities = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,encoder_outputs,decoder_lstm_layer_outputs):\n",
    "        \n",
    "        decoder_lstm_layer_outputs = torch.transpose(decoder_lstm_layer_outputs,dim0=1,dim1=2)\n",
    "        alignment_scores = torch.bmm(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        attention_weights = self.attention_probabilities(alignment_scores)\n",
    "        attention_weights = torch.transpose(attention_weights,dim0=1,dim1=2)\n",
    "        context_vectors = torch.bmm(attention_weights,encoder_outputs)\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,topic_vector_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.first_emebdding_layer = torch.nn.Embedding(num_embeddings=src_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        \n",
    "    def forward(self,X_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_emebdding_layer(X_padded_mini_batch)\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.second_lstm_layer(first_embedding_layer_out)\n",
    "\n",
    "        return encoder_outputs,(final_encoder_output,final_candidate_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.first_embedding_layer = torch.nn.Embedding(num_embeddings=dst_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        self.attention_layer = Attention()\n",
    "        self.output_layer = torch.nn.Linear(in_features=topic_vector_dim*2,out_features=dst_lang_vocab_size)\n",
    "        self.output_layer_activation = torch.nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self,encoder_outputs,initial_hidden_state,initial_candidate_cell_state,\n",
    "                Y_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_embedding_layer(Y_padded_mini_batch)\n",
    "        decoder_lstm_layer_outputs,final_cell_hidden_states = self.second_lstm_layer(first_embedding_layer_out,\n",
    "                                                                                    (initial_hidden_state,\n",
    "                                                                                    initial_candidate_cell_state))\n",
    "        context_vectors = self.attention_layer(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        concatenated_lstm_layer_output = torch.concatenate(tensors=(decoder_lstm_layer_outputs,context_vectors),dim=2)\n",
    "        affine_transformed_output = self.output_layer(concatenated_lstm_layer_output)\n",
    "        decoder_outputs = self.output_layer_activation(affine_transformed_output)\n",
    "\n",
    "        return decoder_outputs, final_cell_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncDecWithAttn(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Seq2SeqEncDecWithAttn,self).__init__()\n",
    "        self.encoder = Encoder(src_lang_vocab_size,topic_vector_dim)\n",
    "        self.decoder = Decoder(dst_lang_vocab_size,topic_vector_dim)\n",
    "\n",
    "    def forward(self,X_padded_mini_batch,Y_padded_mini_batch_input):\n",
    "\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.encoder(X_padded_mini_batch)\n",
    "        Y_hat_mini_batch = self.decoder(encoder_outputs,final_encoder_output,final_candidate_cell_state,\n",
    "                                       Y_padded_mini_batch_input)\n",
    "        \n",
    "        return Y_hat_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_train = X_padded[0:13000]\n",
    "Y_input_padded_train = Y_input_padded[0:13000]\n",
    "Y_label_padded_train = Y_label_padded[0:13000]\n",
    "\n",
    "X_padded_test = X_padded[13000:]\n",
    "Y_input_padded_test = Y_input_padded[13000:]\n",
    "Y_label_padded_test = Y_label_padded[13000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Mini Batch #0, CCE Loss = 8.863893508911133\n",
      "Epoch #0, Mini Batch #25, CCE Loss = 7.972209453582764\n",
      "Epoch #0, Mini Batch #50, CCE Loss = 7.980151653289795\n",
      "Epoch #0, Mini Batch #75, CCE Loss = 7.978329658508301\n",
      "Epoch #0, Mini Batch #100, CCE Loss = 7.994259357452393\n",
      "Epoch #0, Mini Batch #125, CCE Loss = 7.9772868156433105\n",
      "Epoch #0, Mini Batch #150, CCE Loss = 7.957557678222656\n",
      "Epoch #0, Mini Batch #175, CCE Loss = 7.974462985992432\n",
      "Epoch #0, Mini Batch #200, CCE Loss = 7.94850492477417\n",
      "Epoch #0, Mini Batch #225, CCE Loss = 7.9478759765625\n",
      "Epoch #0, Mini Batch #250, CCE Loss = 7.956364154815674\n",
      "Epoch #0, Mini Batch #275, CCE Loss = 7.956339359283447\n",
      "Epoch #0, Mini Batch #300, CCE Loss = 7.937108516693115\n",
      "Epoch #0, Mini Batch #325, CCE Loss = 7.991406440734863\n",
      "Epoch #0, Mini Batch #350, CCE Loss = 7.956931114196777\n",
      "Epoch #0, Mini Batch #375, CCE Loss = 7.943898677825928\n",
      "Epoch #0, Mini Batch #400, CCE Loss = 7.960306644439697\n",
      "Epoch #0, Mini Batch #425, CCE Loss = 7.960865020751953\n",
      "Epoch #0, Mini Batch #450, CCE Loss = 7.9540791511535645\n",
      "Epoch #0, Mini Batch #475, CCE Loss = 7.942198753356934\n",
      "Epoch #1, Mini Batch #0, CCE Loss = 7.939370632171631\n",
      "Epoch #1, Mini Batch #25, CCE Loss = 7.968782424926758\n",
      "Epoch #1, Mini Batch #50, CCE Loss = 7.9800944328308105\n",
      "Epoch #1, Mini Batch #75, CCE Loss = 7.971045017242432\n",
      "Epoch #1, Mini Batch #100, CCE Loss = 7.994234561920166\n",
      "Epoch #1, Mini Batch #125, CCE Loss = 7.97726583480835\n",
      "Epoch #1, Mini Batch #150, CCE Loss = 7.957470893859863\n",
      "Epoch #1, Mini Batch #175, CCE Loss = 7.974438190460205\n",
      "Epoch #1, Mini Batch #200, CCE Loss = 7.9478583335876465\n",
      "Epoch #1, Mini Batch #225, CCE Loss = 7.947854042053223\n",
      "Epoch #1, Mini Batch #250, CCE Loss = 7.95577335357666\n",
      "Epoch #1, Mini Batch #275, CCE Loss = 7.956337928771973\n",
      "Epoch #1, Mini Batch #300, CCE Loss = 7.937107086181641\n",
      "Epoch #1, Mini Batch #325, CCE Loss = 7.991405963897705\n",
      "Epoch #1, Mini Batch #350, CCE Loss = 7.956907749176025\n",
      "Epoch #1, Mini Batch #375, CCE Loss = 7.943894386291504\n",
      "Epoch #1, Mini Batch #400, CCE Loss = 7.960297107696533\n",
      "Epoch #1, Mini Batch #425, CCE Loss = 7.96086311340332\n",
      "Epoch #1, Mini Batch #450, CCE Loss = 7.954075813293457\n",
      "Epoch #1, Mini Batch #475, CCE Loss = 7.942197799682617\n",
      "Epoch #2, Mini Batch #0, CCE Loss = 7.9393696784973145\n",
      "Epoch #2, Mini Batch #25, CCE Loss = 7.968783378601074\n",
      "Epoch #2, Mini Batch #50, CCE Loss = 7.980093002319336\n",
      "Epoch #2, Mini Batch #75, CCE Loss = 7.971044063568115\n",
      "Epoch #2, Mini Batch #100, CCE Loss = 7.994234085083008\n",
      "Epoch #2, Mini Batch #125, CCE Loss = 7.977264881134033\n",
      "Epoch #2, Mini Batch #150, CCE Loss = 7.957469463348389\n",
      "Epoch #2, Mini Batch #175, CCE Loss = 7.974437713623047\n",
      "Epoch #2, Mini Batch #200, CCE Loss = 7.947854042053223\n",
      "Epoch #2, Mini Batch #225, CCE Loss = 7.947854042053223\n",
      "Epoch #2, Mini Batch #250, CCE Loss = 7.957372665405273\n",
      "Epoch #2, Mini Batch #275, CCE Loss = 7.952671527862549\n",
      "Epoch #2, Mini Batch #300, CCE Loss = 7.9365153312683105\n",
      "Epoch #2, Mini Batch #325, CCE Loss = 7.983340263366699\n",
      "Epoch #2, Mini Batch #350, CCE Loss = 7.952322483062744\n",
      "Epoch #2, Mini Batch #375, CCE Loss = 7.944520950317383\n",
      "Epoch #2, Mini Batch #400, CCE Loss = 7.951042652130127\n",
      "Epoch #2, Mini Batch #425, CCE Loss = 7.957947254180908\n",
      "Epoch #2, Mini Batch #450, CCE Loss = 7.953380107879639\n",
      "Epoch #2, Mini Batch #475, CCE Loss = 7.939610004425049\n",
      "Epoch #3, Mini Batch #0, CCE Loss = 7.93585729598999\n",
      "Epoch #3, Mini Batch #25, CCE Loss = 7.96372652053833\n",
      "Epoch #3, Mini Batch #50, CCE Loss = 7.976214408874512\n",
      "Epoch #3, Mini Batch #75, CCE Loss = 7.968784809112549\n",
      "Epoch #3, Mini Batch #100, CCE Loss = 7.989731788635254\n",
      "Epoch #3, Mini Batch #125, CCE Loss = 7.971090316772461\n",
      "Epoch #3, Mini Batch #150, CCE Loss = 7.954659938812256\n",
      "Epoch #3, Mini Batch #175, CCE Loss = 7.967662334442139\n",
      "Epoch #3, Mini Batch #200, CCE Loss = 7.944560527801514\n",
      "Epoch #3, Mini Batch #225, CCE Loss = 7.945030689239502\n",
      "Epoch #3, Mini Batch #250, CCE Loss = 7.953489780426025\n",
      "Epoch #3, Mini Batch #275, CCE Loss = 7.950893402099609\n",
      "Epoch #3, Mini Batch #300, CCE Loss = 7.933809757232666\n",
      "Epoch #3, Mini Batch #325, CCE Loss = 7.982357978820801\n",
      "Epoch #3, Mini Batch #350, CCE Loss = 7.95163106918335\n",
      "Epoch #3, Mini Batch #375, CCE Loss = 7.943345546722412\n",
      "Epoch #3, Mini Batch #400, CCE Loss = 7.950686454772949\n",
      "Epoch #3, Mini Batch #425, CCE Loss = 7.957184314727783\n",
      "Epoch #3, Mini Batch #450, CCE Loss = 7.9529643058776855\n",
      "Epoch #3, Mini Batch #475, CCE Loss = 7.938906192779541\n",
      "Epoch #4, Mini Batch #0, CCE Loss = 7.935857772827148\n",
      "Epoch #4, Mini Batch #25, CCE Loss = 7.963810443878174\n",
      "Epoch #4, Mini Batch #50, CCE Loss = 7.976174354553223\n",
      "Epoch #4, Mini Batch #75, CCE Loss = 7.969084739685059\n",
      "Epoch #4, Mini Batch #100, CCE Loss = 7.989721298217773\n",
      "Epoch #4, Mini Batch #125, CCE Loss = 7.970078945159912\n",
      "Epoch #4, Mini Batch #150, CCE Loss = 7.954086780548096\n",
      "Epoch #4, Mini Batch #175, CCE Loss = 7.968236446380615\n",
      "Epoch #4, Mini Batch #200, CCE Loss = 7.944448947906494\n",
      "Epoch #4, Mini Batch #225, CCE Loss = 7.945028781890869\n",
      "Epoch #4, Mini Batch #250, CCE Loss = 7.952765464782715\n",
      "Epoch #4, Mini Batch #275, CCE Loss = 7.95078182220459\n",
      "Epoch #4, Mini Batch #300, CCE Loss = 7.933711528778076\n",
      "Epoch #4, Mini Batch #325, CCE Loss = 7.980984687805176\n",
      "Epoch #4, Mini Batch #350, CCE Loss = 7.951272964477539\n",
      "Epoch #4, Mini Batch #375, CCE Loss = 7.9410786628723145\n",
      "Epoch #4, Mini Batch #400, CCE Loss = 7.946778774261475\n",
      "Epoch #4, Mini Batch #425, CCE Loss = 7.9560747146606445\n",
      "Epoch #4, Mini Batch #450, CCE Loss = 7.949738502502441\n",
      "Epoch #4, Mini Batch #475, CCE Loss = 7.938846588134766\n"
     ]
    }
   ],
   "source": [
    "nw = Seq2SeqEncDecWithAttn(src_lang_vocab_size=len(Vs),dst_lang_vocab_size=len(Vd),topic_vector_dim=32)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(params=nw.parameters())\n",
    "epochs = 5\n",
    "mb_size = 26\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(X_padded_train.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = X_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_input_train_mb = Y_input_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_label_train_mb = Y_label_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "\n",
    "        Y_label_train_mb = Y_label_train_mb.reshape(Y_label_train_mb.shape[0]*Y_label_train_mb.shape[1],)\n",
    "\n",
    "        Y_pred_train_mb = nw(X_train_mb,Y_input_train_mb)\n",
    "        Y_pred_train_mb = Y_pred_train_mb.reshape(Y_pred_train_mb.shape[0]*Y_pred_train_mb.shape[1],\n",
    "                                                  Y_pred_train_mb.shape[2])\n",
    "        \n",
    "\n",
    "        loss_fn_value = loss_fn(Y_pred_train_mb,Y_label_train_mb)\n",
    "\n",
    "        loss_fn_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(\"Epoch #{}, Mini Batch #{}, CCE Loss = {}\".format(epoch,i,loss_fn_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vd_idx2vocab = dict(zip(Vd.values(),Vd.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(eng_sentence):\n",
    "\n",
    "    tokenized_eng_sentence = tokenizer.tokenize(eng_sentence)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokenized_eng_sentence)\n",
    "    token_ids_tensor = torch.tensor(token_ids)\n",
    "    padded_token_ids = torch.nn.utils.rnn.pad_sequence(token_ids_tensor)\n",
    "\n",
    "    encoder_outputs,(final_encoder_output,final_candidate_cell_state) = nw.encoder(padded_token_ids)\n",
    "    decoder_first_time_step_input = torch.tensor([hindi_vocab[\"<SOS\"]]*mb_size)\n",
    "    decoder_first_time_step_input = torch.unsqueeze(decoder_first_time_step_input,1)\n",
    "    decoder_first_time_step_output, hidden_cell_states = nw.decoder(encoder_outputs,\n",
    "                                                                          final_encoder_output,\n",
    "                                                                          final_candidate_cell_state,\n",
    "                                                                          decoder_first_time_step_input)\n",
    "    \n",
    "    generated_token_id = torch.argmax(decoder_first_time_step_output,1)\n",
    "    generated_token_id = torch.unsqueeze(generated_token_id,1)\n",
    "\n",
    "    print(Vd_idx2vocab[generated_token_id])\n",
    "\n",
    "    for i in range(Nd-1):\n",
    "\n",
    "        generated_softmax_probabilities,hidden_cell_states = nw.decoder(encoder_outputs,\n",
    "                                                                        hidden_cell_states[0],hidden_cell_states[1],\n",
    "                                                                        generated_token_id)\n",
    "        generated_token_id = torch.argmax(generated_softmax_probabilities,1)\n",
    "\n",
    "        if generated_token_id == Vd[\"<EOS\"]:\n",
    "            break\n",
    "\n",
    "        print(Vd_idx2vocab[generated_token_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
