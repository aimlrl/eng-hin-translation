{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-T5/T5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Sentence pairs in English-Hindi - 2025-02-11.tsv\",sep=\"\\t\",header=None,\n",
    "                   names=[\"SrcSentenceID\",\"SrcSentence\",\"DstSentenceID\",\"DstSentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(lambda x: indic_tokenize.trivial_tokenize(x,lang=\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.convert_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vd = set()\n",
    "for tokenized_hindi_sentence in data[\"DstSentence\"]:\n",
    "    Vd.update(tokenized_hindi_sentence)\n",
    "\n",
    "hindi_vocab = dict()\n",
    "for idx, token in enumerate(Vd):\n",
    "    hindi_vocab[token] = idx + 3\n",
    "\n",
    "hindi_vocab[\"<PAD>\"] = 0\n",
    "hindi_vocab[\"<SOS>\"] = 1\n",
    "hindi_vocab[\"<EOS>\"] = 2\n",
    "\n",
    "Vd = hindi_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hindi_tokens_to_ids(tokenized_hindi_sentence):\n",
    "    return [Vd[token] for token in tokenized_hindi_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(convert_hindi_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sos_token_id(hindi_sentence_token_ids_list):\n",
    "    return [1] + hindi_sentence_token_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_eos_token_id(hindi_sentence_token_ids_list):\n",
    "    return hindi_sentence_token_ids_list + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentenceInput\"] = data[\"DstSentence\"].apply(insert_sos_token_id)\n",
    "data[\"DstSentenceLabel\"] = data[\"DstSentence\"].apply(insert_eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=[\"SrcSentenceID\",\"DstSentenceID\",\"DstSentence\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data[\"SrcSentence\"])\n",
    "Y_input = list(data[\"DstSentenceInput\"])\n",
    "Y_label = list(data[\"DstSentenceLabel\"])\n",
    "\n",
    "X_tensor = [torch.tensor(eng_tokenized_ids) for eng_tokenized_ids in X]\n",
    "Y_input_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_input]\n",
    "Y_label_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_label]\n",
    "\n",
    "X_padded = torch.nn.utils.rnn.pad_sequence(X_tensor,batch_first=True)\n",
    "Y_input_padded = torch.nn.utils.rnn.pad_sequence(Y_input_tensor,batch_first=True)\n",
    "Y_label_padded = torch.nn.utils.rnn.pad_sequence(Y_label_tensor,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = X_padded.shape[1]\n",
    "Nd = Y_label_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "        self.attention_probabilities = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,encoder_outputs,decoder_lstm_layer_outputs):\n",
    "        \n",
    "        decoder_lstm_layer_outputs = torch.transpose(decoder_lstm_layer_outputs,dim0=1,dim1=2)\n",
    "        alignment_scores = torch.bmm(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        attention_weights = self.attention_probabilities(alignment_scores)\n",
    "        attention_weights = torch.transpose(attention_weights,dim0=1,dim1=2)\n",
    "        context_vectors = torch.bmm(attention_weights,encoder_outputs)\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,topic_vector_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.first_emebdding_layer = torch.nn.Embedding(num_embeddings=src_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        \n",
    "    def forward(self,X_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_emebdding_layer(X_padded_mini_batch)\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.second_lstm_layer(first_embedding_layer_out)\n",
    "\n",
    "        return encoder_outputs,(final_encoder_output,final_candidate_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.first_embedding_layer = torch.nn.Embedding(num_embeddings=dst_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        self.attention_layer = Attention()\n",
    "        self.output_layer = torch.nn.Linear(in_features=topic_vector_dim*2,out_features=dst_lang_vocab_size)\n",
    "        self.output_layer_activation = torch.nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self,encoder_outputs,initial_hidden_state,initial_candidate_cell_state,\n",
    "                Y_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_embedding_layer(Y_padded_mini_batch)\n",
    "        decoder_lstm_layer_outputs,final_cell_hidden_states = self.second_lstm_layer(first_embedding_layer_out,\n",
    "                                                                                    (initial_hidden_state,\n",
    "                                                                                    initial_candidate_cell_state))\n",
    "        context_vectors = self.attention_layer(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        concatenated_lstm_layer_output = torch.concatenate(tensors=(decoder_lstm_layer_outputs,context_vectors),dim=2)\n",
    "        affine_transformed_output = self.output_layer(concatenated_lstm_layer_output)\n",
    "        decoder_outputs = self.output_layer_activation(affine_transformed_output)\n",
    "\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncDecWithAttn(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Seq2SeqEncDecWithAttn,self).__init__()\n",
    "        self.encoder = Encoder(src_lang_vocab_size,topic_vector_dim)\n",
    "        self.decoder = Decoder(dst_lang_vocab_size,topic_vector_dim)\n",
    "\n",
    "    def forward(self,X_padded_mini_batch,Y_padded_mini_batch_input):\n",
    "\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.encoder(X_padded_mini_batch)\n",
    "        Y_hat_mini_batch = self.decoder(encoder_outputs,final_encoder_output,final_candidate_cell_state,\n",
    "                                       Y_padded_mini_batch_input)\n",
    "        \n",
    "        return Y_hat_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_train = X_padded[0:13000]\n",
    "Y_input_padded_train = Y_input_padded[0:13000]\n",
    "Y_label_padded_train = Y_label_padded[0:13000]\n",
    "\n",
    "X_padded_test = X_padded[13000:]\n",
    "Y_input_padded_test = Y_input_padded[13000:]\n",
    "Y_label_padded_test = Y_label_padded[13000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = Seq2SeqEncDecWithAttn(src_lang_vocab_size=len(Vs),dst_lang_vocab_size=len(Vd),topic_vector_dim=32)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(params=nw.parameters())\n",
    "epochs = 5\n",
    "mb_size = 26\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(X_padded_train.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = X_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_input_train_mb = Y_input_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_label_train_mb = Y_label_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "\n",
    "        Y_label_train_mb = Y_label_train_mb.reshape(Y_label_train_mb.shape[0]*Y_label_train_mb.shape[1],)\n",
    "\n",
    "        Y_pred_train_mb = nw(X_train_mb,Y_input_train_mb)\n",
    "        Y_pred_train_mb = Y_pred_train_mb.reshape(Y_pred_train_mb.shape[0]*Y_pred_train_mb.shape[1],\n",
    "                                                  Y_pred_train_mb.shape[2])\n",
    "        \n",
    "\n",
    "        loss_fn_value = loss_fn(Y_pred_train_mb,Y_label_train_mb)\n",
    "\n",
    "        loss_fn_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(\"Epoch #{}, Mini Batch #{}, CCE Loss = {}\".format(epoch,i,loss_fn_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
